{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f3c7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Drawing the embeddings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep learning: \n",
    "from keras.models import Input, Model\n",
    "from keras.layers import Dense\n",
    "\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8b1d38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   In linguistics word embeddings were discussed in the research area of distributional semantics. It aims to quantify and categorize semantic similarities between linguistic items based on their distributional properties in large samples of language data. The underlying idea that \"a word is characterized by the company it keeps\" was popularized by Firth.\n",
      "0   The technique of representing words as vectors...                                                                                                                                                                                                                                                                                                                \n",
      "1   There are many branches and many research grou...                                                                                                                                                                                                                                                                                                                \n",
      "2                                         Limitations                                                                                                                                                                                                                                                                                                                \n",
      "3   One of the main limitations of word embeddings...                                                                                                                                                                                                                                                                                                                \n",
      "4                For biological sequences: BioVectors                                                                                                                                                                                                                                                                                                                \n",
      "5   Word embeddings for n-grams in biological sequ...                                                                                                                                                                                                                                                                                                                \n",
      "6                                     Thought vectors                                                                                                                                                                                                                                                                                                                \n",
      "7   Thought vectors are an extension of word embed...                                                                                                                                                                                                                                                                                                                \n",
      "8                                            Software                                                                                                                                                                                                                                                                                                                \n",
      "9   Software for training and using word embedding...                                                                                                                                                                                                                                                                                                                \n",
      "10                            Examples of application                                                                                                                                                                                                                                                                                                                \n",
      "11  For instance, the fastText is also used to cal...                                                                                                                                                                                                                                                                                                                \n"
     ]
    }
   ],
   "source": [
    "# Reading the text from the input folder\n",
    "texts = pd.read_table('w2v.txt')\n",
    "# texts = [x for x in texts['text']]\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "773ed630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In linguistics word embeddings were discussed in the research area of distributional semantics. It aims to quantify and categorize semantic similarities between linguistic items based on their distributional properties in large samples of language data. The underlying idea that \"a word is characterized by the company it keeps\" was popularized by Firth.\\n', '\\n', 'The technique of representing words as vectors has roots in the 1960s with the development of the vector space model for information retrieval. Reducing the number of dimensions using singular value decomposition then led to the introduction of latent semantic analysis in the late 1980s.In 2000 Bengio et al. provided in a series of papers the \"Neural probabilistic language models\" to reduce the high dimensionality of words representations in contexts by \"learning a distributed representation for words\". (Bengio et al, 2003). Word embeddings come in two different styles, one in which words are expressed as vectors of co-occurring words, and another in which words are expressed as vectors of linguistic contexts in which the words occur; these different styles are studied in (Lavelli et al, 2004). Roweis and Saul published in Science how to use \"locally linear embedding\" (LLE) to discover representations of high dimensional data structures. The area developed gradually and really took off after 2010, partly because important advances had been made since then on the quality of vectors and the training speed of the model.\\n', '\\n', 'There are many branches and many research groups working on word embeddings. In 2013, a team at Google led by Tomas Mikolov created word2vec, a word embedding toolkit which can train vector space models faster than the previous approaches. Most new word embedding techniques rely on a neural network architecture instead of more traditional n-gram models and unsupervised learning.\\n', '\\n', 'Limitations\\n', 'One of the main limitations of word embeddings (word vector space models in general) is that possible meanings of a word are conflated into a single representation (a single vector in the semantic space). Sense embeddings are a solution to this problem: individual meanings of words are represented as distinct vectors in the space.\\n', '\\n', 'For biological sequences: BioVectors\\n', 'Word embeddings for n-grams in biological sequences (e.g. DNA, RNA, and Proteins) for bioinformatics applications have been proposed by Asgari and Mofrad. Named bio-vectors (BioVec) to refer to biological sequences in general with protein-vectors (ProtVec) for proteins (amino-acid sequences) and gene-vectors (GeneVec) for gene sequences, this representation can be widely used in applications of deep learning in proteomics and genomics. The results presented by Asgari and Mofrad suggest that BioVectors can characterize biological sequences in terms of biochemical and biophysical interpretations of the underlying patterns.\\n', '\\n', 'Thought vectors\\n', 'Thought vectors are an extension of word embeddings to entire sentences or even documents. Some researchers hope that these can improve the quality of machine translation.\\n', '\\n', 'Software\\n', \"Software for training and using word embeddings includes Tomas Mikolov's Word2vec, Stanford University's GloVe, AllenNLP's Elmo,fastText, Gensim, Indra and Deeplearning4j. Principal Component Analysis (PCA) and T-Distributed Stochastic Neighbour Embedding (t-SNE) are both used to reduce the dimensionality of word vector spaces and visualize word embeddings and clusters.\\n\", '\\n', 'Examples of application\\n', 'For instance, the fastText is also used to calculate word embeddings for text corpora in Sketch Engine that are available online.']\n"
     ]
    }
   ],
   "source": [
    "my_file = open(\"w2v.txt\", \"r\")\n",
    "content_list = my_file.readlines()\n",
    "print(content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b283821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In linguistics word embeddings were discussed in the research area of distributional semantics. It aims to quantify and categorize semantic similarities between linguistic items based on their distributional properties in large samples of language data. The underlying idea that \"a word is characterized by the company it keeps\" was popularized by Firth.\n",
      "\n",
      "The technique of representing words as vectors has roots in the 1960s with the development of the vector space model for information retrieval. Reducing the number of dimensions using singular value decomposition then led to the introduction of latent semantic analysis in the late 1980s.In 2000 Bengio et al. provided in a series of papers the \"Neural probabilistic language models\" to reduce the high dimensionality of words representations in contexts by \"learning a distributed representation for words\". (Bengio et al, 2003). Word embeddings come in two different styles, one in which words are expressed as vectors of co-occurring words, and another in which words are expressed as vectors of linguistic contexts in which the words occur; these different styles are studied in (Lavelli et al, 2004). Roweis and Saul published in Science how to use \"locally linear embedding\" (LLE) to discover representations of high dimensional data structures. The area developed gradually and really took off after 2010, partly because important advances had been made since then on the quality of vectors and the training speed of the model.\n",
      "\n",
      "There are many branches and many research groups working on word embeddings. In 2013, a team at Google led by Tomas Mikolov created word2vec, a word embedding toolkit which can train vector space models faster than the previous approaches. Most new word embedding techniques rely on a neural network architecture instead of more traditional n-gram models and unsupervised learning.\n",
      "\n",
      "Limitations\n",
      "One of the main limitations of word embeddings (word vector space models in general) is that possible meanings of a word are conflated into a single representation (a single vector in the semantic space). Sense embeddings are a solution to this problem: individual meanings of words are represented as distinct vectors in the space.\n",
      "\n",
      "For biological sequences: BioVectors\n",
      "Word embeddings for n-grams in biological sequences (e.g. DNA, RNA, and Proteins) for bioinformatics applications have been proposed by Asgari and Mofrad. Named bio-vectors (BioVec) to refer to biological sequences in general with protein-vectors (ProtVec) for proteins (amino-acid sequences) and gene-vectors (GeneVec) for gene sequences, this representation can be widely used in applications of deep learning in proteomics and genomics. The results presented by Asgari and Mofrad suggest that BioVectors can characterize biological sequences in terms of biochemical and biophysical interpretations of the underlying patterns.\n",
      "\n",
      "Thought vectors\n",
      "Thought vectors are an extension of word embeddings to entire sentences or even documents. Some researchers hope that these can improve the quality of machine translation.\n",
      "\n",
      "Software\n",
      "Software for training and using word embeddings includes Tomas Mikolov's Word2vec, Stanford University's GloVe, AllenNLP's Elmo,fastText, Gensim, Indra and Deeplearning4j. Principal Component Analysis (PCA) and T-Distributed Stochastic Neighbour Embedding (t-SNE) are both used to reduce the dimensionality of word vector spaces and visualize word embeddings and clusters.\n",
      "\n",
      "Examples of application\n",
      "For instance, the fastText is also used to calculate word embeddings for text corpora in Sketch Engine that are available online.\n"
     ]
    }
   ],
   "source": [
    "my_file = open(\"w2v.txt\", \"r\")\n",
    "content = my_file.read()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b379911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the window for context\n",
    "window = 2\n",
    "\n",
    "# Creating a placeholder for the scanning of the word list\n",
    "word_lists = []\n",
    "all_text = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6421780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the window for context\n",
    "window = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8274e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_unique_word_dict(text:list) -> dict:\n",
    "    \"\"\"\n",
    "    A method that creates a dictionary where the keys are unique words\n",
    "    and key values are indices\n",
    "    \"\"\"\n",
    "    # Getting all the unique words from our text and sorting them alphabetically\n",
    "    words = list(set(text))\n",
    "    words.sort()\n",
    "\n",
    "    # Creating the dictionary for the unique words\n",
    "    unique_word_dict = {}\n",
    "    for i, word in enumerate(words):\n",
    "        unique_word_dict.update({\n",
    "            word: i\n",
    "        })\n",
    "\n",
    "    return unique_word_dict    \n",
    "\n",
    "def text_preprocessing(\n",
    "    text:list,\n",
    "    punctuations = r'''!()-[]{};:'\"\\,<>./?@#$%^&*_“~''',\n",
    "    stop_words=['and', 'a', 'is', 'the', 'in', 'be', 'will','on','to','an','are']\n",
    "    )->list:\n",
    "    \"\"\"\n",
    "    A method to preproces text\n",
    "    \"\"\"\n",
    "    for x in text.lower(): \n",
    "        if x in punctuations: \n",
    "            text = text.replace(x, \"\")\n",
    "\n",
    "    # Removing words that have numbers in them\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "\n",
    "    # Removing digits\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "\n",
    "    # Cleaning the whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Setting every word to lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # Converting all our text to a list \n",
    "    text = text.split(' ')\n",
    "\n",
    "    # Droping empty strings\n",
    "    text = [x for x in text if x!='']\n",
    "\n",
    "    # Droping stop words\n",
    "    text = [x for x in text if x not in stop_words]\n",
    "\n",
    "    return text\n",
    "\n",
    "# Functions to find the most similar word \n",
    "def euclidean(vec1:np.array, vec2:np.array) -> float:\n",
    "    \"\"\"\n",
    "    A function to calculate the euclidean distance between two vectors\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((vec1 - vec2)**2))\n",
    "\n",
    "def find_similar(word:str, embedding_dict:dict, top_n=10)->list:\n",
    "    \"\"\"\n",
    "    A method to find the most similar word based on the learnt embeddings\n",
    "    \"\"\"\n",
    "    dist_dict = {}\n",
    "    word_vector = embedding_dict.get(word, [])\n",
    "    if len(word_vector) > 0:\n",
    "        for key, value in embedding_dict.items():\n",
    "            if key!=word:\n",
    "                dist = euclidean(word_vector, value)\n",
    "                dist_dict.update({\n",
    "                    key: dist\n",
    "                })\n",
    "\n",
    "        return sorted(dist_dict.items(), key=lambda x: x[1])[0:top_n]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0c8c0b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a placeholder for the scanning of the word list\n",
    "word_lists = []\n",
    "all_text = []\n",
    "\n",
    "for text in texts:\n",
    "\n",
    "    # Cleaning the text\n",
    "    text = text_preprocessing(text)\n",
    "\n",
    "    # Appending to the all text list\n",
    "    all_text += text \n",
    "\n",
    "    # Creating a context dictionary\n",
    "    for i, word in enumerate(text):\n",
    "        for w in range(window):\n",
    "            # Getting the context that is ahead by *window* words\n",
    "            if i + 1 + w < len(text): \n",
    "                word_lists.append([word] + [text[(i + 1 + w)]])\n",
    "            # Getting the context that is behind by *window* words    \n",
    "            if i - w - 1 >= 0:\n",
    "                word_lists.append([word] + [text[(i - w - 1)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d9bafa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['linguistics', 'word'],\n",
       " ['linguistics', 'embeddings'],\n",
       " ['word', 'embeddings'],\n",
       " ['word', 'linguistics'],\n",
       " ['word', 'were'],\n",
       " ['embeddings', 'were'],\n",
       " ['embeddings', 'word'],\n",
       " ['embeddings', 'discussed'],\n",
       " ['embeddings', 'linguistics'],\n",
       " ['were', 'discussed'],\n",
       " ['were', 'embeddings'],\n",
       " ['were', 'research'],\n",
       " ['were', 'word'],\n",
       " ['discussed', 'research'],\n",
       " ['discussed', 'were'],\n",
       " ['discussed', 'area'],\n",
       " ['discussed', 'embeddings'],\n",
       " ['research', 'area'],\n",
       " ['research', 'discussed'],\n",
       " ['research', 'of'],\n",
       " ['research', 'were'],\n",
       " ['area', 'of'],\n",
       " ['area', 'research'],\n",
       " ['area', 'distributional'],\n",
       " ['area', 'discussed'],\n",
       " ['of', 'distributional'],\n",
       " ['of', 'area'],\n",
       " ['of', 'semantics'],\n",
       " ['of', 'research'],\n",
       " ['distributional', 'semantics'],\n",
       " ['distributional', 'of'],\n",
       " ['distributional', 'it'],\n",
       " ['distributional', 'area'],\n",
       " ['semantics', 'it'],\n",
       " ['semantics', 'distributional'],\n",
       " ['semantics', 'aims'],\n",
       " ['semantics', 'of'],\n",
       " ['it', 'aims'],\n",
       " ['it', 'semantics'],\n",
       " ['it', 'quantify'],\n",
       " ['it', 'distributional'],\n",
       " ['aims', 'quantify'],\n",
       " ['aims', 'it'],\n",
       " ['aims', 'categorize'],\n",
       " ['aims', 'semantics'],\n",
       " ['quantify', 'categorize'],\n",
       " ['quantify', 'aims'],\n",
       " ['quantify', 'semantic'],\n",
       " ['quantify', 'it'],\n",
       " ['categorize', 'semantic'],\n",
       " ['categorize', 'quantify'],\n",
       " ['categorize', 'similarities'],\n",
       " ['categorize', 'aims'],\n",
       " ['semantic', 'similarities'],\n",
       " ['semantic', 'categorize'],\n",
       " ['semantic', 'between'],\n",
       " ['semantic', 'quantify'],\n",
       " ['similarities', 'between'],\n",
       " ['similarities', 'semantic'],\n",
       " ['similarities', 'linguistic'],\n",
       " ['similarities', 'categorize'],\n",
       " ['between', 'linguistic'],\n",
       " ['between', 'similarities'],\n",
       " ['between', 'items'],\n",
       " ['between', 'semantic'],\n",
       " ['linguistic', 'items'],\n",
       " ['linguistic', 'between'],\n",
       " ['linguistic', 'based'],\n",
       " ['linguistic', 'similarities'],\n",
       " ['items', 'based'],\n",
       " ['items', 'linguistic'],\n",
       " ['items', 'their'],\n",
       " ['items', 'between'],\n",
       " ['based', 'their'],\n",
       " ['based', 'items'],\n",
       " ['based', 'distributional'],\n",
       " ['based', 'linguistic'],\n",
       " ['their', 'distributional'],\n",
       " ['their', 'based'],\n",
       " ['their', 'properties'],\n",
       " ['their', 'items'],\n",
       " ['distributional', 'properties'],\n",
       " ['distributional', 'their'],\n",
       " ['distributional', 'large'],\n",
       " ['distributional', 'based'],\n",
       " ['properties', 'large'],\n",
       " ['properties', 'distributional'],\n",
       " ['properties', 'samples'],\n",
       " ['properties', 'their'],\n",
       " ['large', 'samples'],\n",
       " ['large', 'properties'],\n",
       " ['large', 'of'],\n",
       " ['large', 'distributional'],\n",
       " ['samples', 'of'],\n",
       " ['samples', 'large'],\n",
       " ['samples', 'language'],\n",
       " ['samples', 'properties'],\n",
       " ['of', 'language'],\n",
       " ['of', 'samples'],\n",
       " ['of', 'data'],\n",
       " ['of', 'large'],\n",
       " ['language', 'data'],\n",
       " ['language', 'of'],\n",
       " ['language', 'underlying'],\n",
       " ['language', 'samples'],\n",
       " ['data', 'underlying'],\n",
       " ['data', 'language'],\n",
       " ['data', 'idea'],\n",
       " ['data', 'of'],\n",
       " ['underlying', 'idea'],\n",
       " ['underlying', 'data'],\n",
       " ['underlying', 'that'],\n",
       " ['underlying', 'language'],\n",
       " ['idea', 'that'],\n",
       " ['idea', 'underlying'],\n",
       " ['idea', 'word'],\n",
       " ['idea', 'data'],\n",
       " ['that', 'word'],\n",
       " ['that', 'idea'],\n",
       " ['that', 'characterized'],\n",
       " ['that', 'underlying'],\n",
       " ['word', 'characterized'],\n",
       " ['word', 'that'],\n",
       " ['word', 'by'],\n",
       " ['word', 'idea'],\n",
       " ['characterized', 'by'],\n",
       " ['characterized', 'word'],\n",
       " ['characterized', 'company'],\n",
       " ['characterized', 'that'],\n",
       " ['by', 'company'],\n",
       " ['by', 'characterized'],\n",
       " ['by', 'it'],\n",
       " ['by', 'word'],\n",
       " ['company', 'it'],\n",
       " ['company', 'by'],\n",
       " ['company', 'keeps'],\n",
       " ['company', 'characterized'],\n",
       " ['it', 'keeps'],\n",
       " ['it', 'company'],\n",
       " ['it', 'was'],\n",
       " ['it', 'by'],\n",
       " ['keeps', 'was'],\n",
       " ['keeps', 'it'],\n",
       " ['keeps', 'popularized'],\n",
       " ['keeps', 'company'],\n",
       " ['was', 'popularized'],\n",
       " ['was', 'keeps'],\n",
       " ['was', 'by'],\n",
       " ['was', 'it'],\n",
       " ['popularized', 'by'],\n",
       " ['popularized', 'was'],\n",
       " ['popularized', 'firth'],\n",
       " ['popularized', 'keeps'],\n",
       " ['by', 'firth'],\n",
       " ['by', 'popularized'],\n",
       " ['by', 'was'],\n",
       " ['firth', 'by'],\n",
       " ['firth', 'popularized']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a125960",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "158it [00:00, 158124.56it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_word_dict = create_unique_word_dict(all_text)\n",
    "\n",
    "# Defining the number of features (unique words)\n",
    "n_words = len(unique_word_dict)\n",
    "\n",
    "# Getting all the unique words \n",
    "words = list(unique_word_dict.keys())\n",
    "\n",
    "# Creating the X and Y matrices using one hot encoding\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i, word_list in tqdm(enumerate(word_lists)):\n",
    "    # Getting the indices\n",
    "    main_word_index = unique_word_dict.get(word_list[0])\n",
    "    context_word_index = unique_word_dict.get(word_list[1])\n",
    "\n",
    "    # Creating the placeholders   \n",
    "    X_row = np.zeros(n_words)\n",
    "    Y_row = np.zeros(n_words)\n",
    "\n",
    "    # One hot encoding the main word\n",
    "    X_row[main_word_index] = 1\n",
    "\n",
    "    # One hot encoding the Y matrix words \n",
    "    Y_row[context_word_index] = 1\n",
    "\n",
    "    # Appending to the main matrices\n",
    "    X.append(X_row)\n",
    "    Y.append(Y_row)\n",
    "\n",
    "# Converting the matrices into a sparse format because the vast majority of the data are 0s\n",
    "# X = sparse.csr_matrix(X)\n",
    "# Y = sparse.csr_matrix(Y)\n",
    "\n",
    "# Defining the size of the embedding\n",
    "embed_size = 2\n",
    "\n",
    "# Defining the neural network\n",
    "inp = Input(shape=(len(X),))\n",
    "x = Dense(units=embed_size, activation='linear')(inp)\n",
    "x = Dense(units=len(Y), activation='softmax')(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfae3773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ebb30f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\nismai01\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:830 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\nismai01\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:813 run_step  *\n        outputs = model.train_step(data)\n    C:\\Users\\nismai01\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:770 train_step  *\n        y_pred = self(x, training=True)\n    C:\\Users\\nismai01\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:989 __call__  *\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\nismai01\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:197 assert_input_compatibility  *\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer model expects 1 input(s), but it received 158 input tensors. Inputs received: [<tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_36:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_37:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_38:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_39:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_40:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_41:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_42:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_43:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_44:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_45:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_46:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_47:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_48:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_49:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_50:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_51:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_52:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_53:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_54:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_55:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_56:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_57:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_58:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_59:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_60:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_61:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_62:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_63:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_64:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_65:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_66:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_67:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_68:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_69:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_70:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_71:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_72:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_73:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_74:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_75:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_76:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_77:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_78:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_79:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_80:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_81:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_82:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_83:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_84:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_85:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_86:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_87:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_88:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_89:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_90:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_91:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_92:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_93:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_94:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_95:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_96:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_97:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_98:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_99:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_100:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_101:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_102:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_103:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_104:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_105:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_106:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_107:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_108:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_109:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_110:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_111:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_112:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_113:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_114:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_115:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_116:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_117:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_118:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_119:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_120:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_121:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_122:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_123:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_124:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_125:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_126:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_127:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_128:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_129:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_130:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_131:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_132:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_133:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_134:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_135:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_136:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_137:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_138:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_139:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_140:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_141:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_142:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_143:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_144:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_145:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_146:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_147:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_148:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_149:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_150:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_151:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_152:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_153:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_154:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_155:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_156:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_157:0' shape=(None, 1) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ce15a7e82aea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Optimizing the network weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1156\u001b[0m                 _r=1):\n\u001b[0;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\nismai01\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:830 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\nismai01\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:813 run_step  *\n        outputs = model.train_step(data)\n    C:\\Users\\nismai01\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:770 train_step  *\n        y_pred = self(x, training=True)\n    C:\\Users\\nismai01\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:989 __call__  *\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\nismai01\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:197 assert_input_compatibility  *\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer model expects 1 input(s), but it received 158 input tensors. Inputs received: [<tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_36:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_37:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_38:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_39:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_40:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_41:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_42:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_43:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_44:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_45:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_46:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_47:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_48:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_49:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_50:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_51:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_52:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_53:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_54:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_55:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_56:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_57:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_58:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_59:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_60:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_61:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_62:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_63:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_64:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_65:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_66:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_67:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_68:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_69:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_70:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_71:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_72:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_73:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_74:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_75:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_76:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_77:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_78:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_79:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_80:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_81:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_82:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_83:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_84:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_85:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_86:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_87:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_88:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_89:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_90:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_91:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_92:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_93:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_94:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_95:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_96:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_97:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_98:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_99:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_100:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_101:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_102:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_103:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_104:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_105:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_106:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_107:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_108:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_109:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_110:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_111:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_112:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_113:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_114:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_115:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_116:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_117:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_118:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_119:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_120:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_121:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_122:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_123:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_124:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_125:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_126:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_127:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_128:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_129:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_130:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_131:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_132:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_133:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_134:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_135:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_136:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_137:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_138:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_139:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_140:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_141:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_142:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_143:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_144:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_145:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_146:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_147:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_148:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_149:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_150:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_151:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_152:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_153:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_154:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_155:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_156:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'ExpandDims_157:0' shape=(None, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# Optimizing the network weights\n",
    "model.fit(\n",
    "    x=X, \n",
    "    y=Y, \n",
    "    batch_size=10,\n",
    "    epochs=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d05304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the weights from the neural network. \n",
    "# These are the so called word embeddings\n",
    "# The input layer \n",
    "weights = model.get_weights()[0]\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to store the embeddings in. The key is a unique word and \n",
    "# the value is the numeric vector\n",
    "embedding_dict = {}\n",
    "for word in words: \n",
    "    embedding_dict.update({\n",
    "        word: weights[unique_word_dict.get(word)]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting the embeddings\n",
    "plt.figure(figsize=(10, 10))\n",
    "for word in list(unique_word_dict.keys()):\n",
    "    coord = embedding_dict.get(word)\n",
    "    plt.scatter(coord[0], coord[1])\n",
    "    plt.annotate(word, (coord[0], coord[1]))       \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
